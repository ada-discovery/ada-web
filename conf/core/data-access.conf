# Database configuration
# ~~~~~
# DO NOT EDIT/UPDATE IN PRODUCTION BUT USE custom.conf TO OVERRIDE!

///////////
// Mongo //
///////////

mongodb.db = "ada"
mongodb.db = ${?ADA_MONGO_DB_NAME}

mongodb.host = "localhost:27017"
mongodb.host = ${?ADA_MONGO_DB_HOST}

mongodb.username = "mongo_user"
mongodb.username = ${?ADA_MONGO_DB_USERNAME}

mongodb.password = "changeme"
mongodb.password = ${?ADA_MONGO_DB_PASSWORD}

# mongodb.uri ="mongodb://"${mongodb.host}"/"${mongodb.db}"?connectTimeoutMS=30000&socketTimeoutMS=30000&rm.keepAlive=true"
mongodb.uri = "mongodb://"${mongodb.username}":"${mongodb.password}"@"${mongodb.host}"/"${mongodb.db}"?authMode=scram-sha1&rm.nbChannelsPerNode=20"
mongodb.uri = ${?ADA_MONGO_DB_URI}

mongodb.connection.strictUri=true


////////////////////
// Elastic Search //
////////////////////

// default values
elastic.uri = "127.0.0.1:9200"
elastic.cluster.name = "elasticsearch"
elastic.threadpool.index.size = 10
elastic.threadpool.bulk.size = 10

elastic {
  uri: ${?ADA_ELASTIC_DB_HOST}
  cluster.name: ${?ADA_ELASTIC_DB_CLUSTER_NAME}
  type: "transport"
  client.transport.sniff: true
  client.transport.ping_timeout: 80s
  thread_pool.index.size: ${?ADA_ELASTIC_THREADPOOL_INDEX_SIZE}
  thread_pool.index.queue_size: 10000
  thread_pool.bulk.size: ${?ADA_ELASTIC_THREADPOOL_BULK_SIZE}
  thread_pool.bulk.queue_size: 1000
  scroll.batch.size: 10000
  scroll.doc_sort.use: true
  index.fields.limit: 20000
//  text.analyzer: "standard"
}